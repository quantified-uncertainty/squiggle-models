## AI safety technical research

<https://80000hours.org/career-reviews/ai-safety-researcher/>

## Pathway to impact of: AI Safety Technical Research

Preliminaries -> AI safety research -> Chance of aligning otherwise unaligned AI -> Flourishing future

Preliminaries:

- PhD program in ML -> Getting work at a top AI lab -> Working on a worthy research approach -> ...
- Reading things online -> Getting an EA grant to do independent research -> Finding or developing a worthy agenda -> ...

## Estimation strategy

1. Approximate the long-run value of humanity very informally

- Make simplifying assumptions (non-zero discounting, steady-state population) in order to get a non-infinite value.
- These assumptions may not be realistic or philosophically neat, but they are useful for providing a _lower bound_

2. Approximate the probability for each step on the pathway to impact:

- Probability of passsing through the preliminary stages
- Probability of choosing a worthy research agenda
- Probability that the research agenda will succeed at its own goals
- Probability that research success will avoid a catastrophe.

3. Combine both estimates
