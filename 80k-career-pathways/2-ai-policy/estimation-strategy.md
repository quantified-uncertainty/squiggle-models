# Long-term AI policy strategy research and implementation

<https://80000hours.org/career-reviews/ai-policy-and-strategy/>

## Pathway to impact

Go to good school -> Get into politics -> Get position of power -> Implement good AI governance ideas.

## Estimation strategy

(Similar to the estimation for AI safety technical research)

1. Approximate the long-run value of humanity very informally

- Make simplifying assumptions (non-zero discounting, steady-state population) in order to get a non-infinite value.
- These assumptions may not be realistic or philosophically neat, but they are useful for providing a _lower bound_

2. Approximate the probability for each step on the pathway to impact:

- Probability of attaining some measure of power
- Probability of using that measure of power to pass through some AI policy bill or regulation
- Probability that bill of regulation affects a castrophe
- Uncertainty of the sign of the impact of regulation

3. Combine both estimates
